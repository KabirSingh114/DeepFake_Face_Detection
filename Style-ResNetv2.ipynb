{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, Lambda, Dropout\n",
    "from keras.layers import SeparableConv2D, Add, Convolution2D, concatenate, Layer, ReLU, DepthwiseConv2D, Reshape, Multiply, InputSpec\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import brentq\n",
    "from scipy.interpolate import interp1d\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import random\n",
    "from keras.applications import Xception, ResNet101V2\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2  # number of classes\n",
    "img_width, img_height = 64, 64  # change based on the shape/structure of your images\n",
    "batch_size = 128  # try 4, 8, 16, 32, 64, 128, 256 dependent on CPU/GPU memory capacity (powers of 2 values).\n",
    "nb_epoch = 300  # number of iteration the algorithm gets trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/home/www/fake_detection/StyleGAN/train'\n",
    "validation_dir = '/home/www/fake_detection/StyleGAN/validation'\n",
    "test50_dir = '/home/www/fake_detection/StyleGAN/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/www/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"resnet101v2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 16, 16, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 16, 16, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 16, 16, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 16, 16, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 16, 16, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 16, 16, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 16, 16, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 8, 8, 256)    0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 8, 8, 256)    0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 8, 8, 512)    0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 4, 4, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 4, 4, 512)    0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 4, 4, 512)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 4, 4, 512)    0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 4, 4, 256)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 4, 4, 256)    0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, 4, 4, 1024)   0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 4, 4, 256)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 4, 4, 256)    0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, 4, 4, 1024)   0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 4, 4, 256)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 4, 4, 256)    0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, 4, 4, 1024)   0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, 4, 4, 1024)   0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, 4, 4, 1024)   0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, 4, 4, 1024)   0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, 4, 4, 1024)   0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, 4, 4, 1024)   0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, 4, 4, 1024)   0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, 4, 4, 1024)   0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, 4, 4, 1024)   0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, 4, 4, 1024)   0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, 4, 4, 1024)   0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, 4, 4, 1024)   0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, 4, 4, 1024)   0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, 4, 4, 1024)   0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 2, 2, 256)    589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 2, 2, 256)    1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 2, 2, 256)    0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 1024)   0           conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, 2, 2, 1024)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 2, 2, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 2, 2, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 2, 2, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 2, 2, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 2, 2, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 2, 2, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 2, 2, 2048)   0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 2)            4098        avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 42,630,658\n",
      "Trainable params: 42,532,994\n",
      "Non-trainable params: 97,664\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ResNet101V2(include_top=True, weights=None, input_shape=(img_width, img_height, 3), classes=2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_datagen = ImageDataGenerator(rescale=1./255, )\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "#                                                         target_size=(img_height, img_width),\n",
    "#                                                         batch_size=batch_size,\n",
    "#                                                         shuffle=True,\n",
    "#                                                         class_mode='categorical')\n",
    "\n",
    "# validation_generator = train_datagen.flow_from_directory(validation_dir,\n",
    "#                                                         target_size=(img_height, img_width),\n",
    "#                                                         batch_size=batch_size,\n",
    "#                                                         shuffle=False,\n",
    "#                                                         class_mode='categorical')\n",
    "\n",
    "# test50_generator = test_datagen.flow_from_directory(test50_dir,\n",
    "#                                                   target_size=(img_height, img_width),\n",
    "#                                                   batch_size=batch_size,\n",
    "#                                                   shuffle=False,\n",
    "#                                                   class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback_list = [EarlyStopping(monitor='val_accuracy', patience=10),\n",
    "#                  ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)]\n",
    "# history = model.fit_generator(train_generator,\n",
    "#                             steps_per_epoch=200,\n",
    "#                             epochs=100,\n",
    "#                             validation_data=validation_generator,\n",
    "#                             validation_steps=len(validation_generator),\n",
    "#                             callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('/home/www/fake_detection/model/style_resnetv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('/home/www/fake_detection/model/style_resnetv2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = model.predict_generator(test50_generator, steps=len(test50_generator), verbose=1)\n",
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "# print(test50_generator.class_indices)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_score50 = []\n",
    "# output_class50 = []\n",
    "# answer_class50 = []\n",
    "# answer_class50_1 =[]\n",
    "\n",
    "# for i in trange(len(test50_generator)):\n",
    "#     output50 = model.predict_on_batch(test50_generator[i][0])\n",
    "#     output_score50.append(output50)\n",
    "#     answer_class50.append(test50_generator[i][1])\n",
    "    \n",
    "# output_score50 = np.concatenate(output_score50)\n",
    "# answer_class50 = np.concatenate(answer_class50)\n",
    "\n",
    "# output_class50 = np.argmax(output_score50, axis=1)\n",
    "# answer_class50_1 = np.argmax(answer_class50, axis=1)\n",
    "\n",
    "# print(output_class50)\n",
    "# print(answer_class50_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm50 = confusion_matrix(answer_class50_1, output_class50)\n",
    "# report50 = classification_report(answer_class50_1, output_class50)\n",
    "\n",
    "# recall50 = cm50[0][0] / (cm50[0][0] + cm50[0][1])\n",
    "# fallout50 = cm50[1][0] / (cm50[1][0] + cm50[1][1])\n",
    "\n",
    "# fpr50, tpr50, thresholds50 = roc_curve(answer_class50_1, output_score50[:, 1], pos_label=1.)\n",
    "# eer50 = brentq(lambda x : 1. - x - interp1d(fpr50, tpr50)(x), 0., 1.)\n",
    "# thresh50 = interp1d(fpr50, thresholds50)(eer50)\n",
    "\n",
    "# print(report50)\n",
    "# print(cm50)\n",
    "# print(\"AUROC: %f\" %(roc_auc_score(answer_class50_1, output_score50[:, 1])))\n",
    "# print(thresh50)\n",
    "# print('test_acc: ', len(output_class50[np.equal(output_class50, answer_class50_1)]) / len(output_class50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout(img):\n",
    "    \"\"\"\n",
    "    # Function: RandomCrop (ZeroPadded (4, 4)) + random occulusion image\n",
    "    # Arguments:\n",
    "        img: image\n",
    "    # Returns:\n",
    "        img\n",
    "    \"\"\"\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    channels = img.shape[2]\n",
    "    MAX_CUTS = 3 # chance to get more cuts\n",
    "    MAX_LENGTH_MUTIPLIER = 5 # chance to get larger cuts\n",
    "    # 16 for cifar10, 8 for cifar100\n",
    "    \n",
    "    # Zero-padded (4, 4)\n",
    "#     img = np.pad(img, ((4,4),(4,4),(0,0)), mode='constant', constant_values=(0))\n",
    "    \n",
    "#     # random-crop 64x64\n",
    "#     dy, dx = height, width\n",
    "#     x = np.random.randint(0, width - dx + 1)\n",
    "#     y = np.random.randint(0, height - dy + 1)\n",
    "#     img = img[y:(y+dy), x:(x+dx)]\n",
    "    \n",
    "#     mean norm\n",
    "#     mean = img.mean(keepdims=True)\n",
    "#     img -= mean\n",
    "\n",
    "    img *= 1./255\n",
    "    \n",
    "    mask = np.ones((height, width, channels), dtype=np.float32)\n",
    "    nb_cuts = np.random.randint(0, MAX_CUTS + 1)\n",
    "    \n",
    "    # cutout\n",
    "    for i in range(nb_cuts):\n",
    "        y = np.random.randint(height)\n",
    "        x = np.random.randint(width)\n",
    "        length = 4 * np.random.randint(1, MAX_LENGTH_MUTIPLIER+1)\n",
    "        \n",
    "        y1 = np.clip(y-length//2, 0, height)\n",
    "        y2 = np.clip(y+length//2, 0, height)\n",
    "        x1 = np.clip(x-length//2, 0, width)\n",
    "        x2 = np.clip(x+length//2, 0, width)\n",
    "        \n",
    "        mask[y1:y2, x1:x2, :] = 0.\n",
    "    \n",
    "    img = img * mask\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU6(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"ReLU6\")\n",
    "        self.relu6 = ReLU(max_value=6, name=\"ReLU6\")\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.relu6(input)\n",
    "\n",
    "\n",
    "class HardSigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu6 = ReLU6()\n",
    "\n",
    "    def call(self, input):\n",
    "        return self.relu6(input + 3.0) / 6.0\n",
    "\n",
    "\n",
    "class HardSwish(Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hard_sigmoid = HardSigmoid()\n",
    "\n",
    "    def call(self, input):\n",
    "        return input * self.hard_sigmoid(input)\n",
    "    \n",
    "class Attention(Layer):\n",
    "    def __init__(self, ch, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        self.channels = ch\n",
    "        self.filters_f_g = self.channels // 8\n",
    "        self.filters_h = self.channels\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        kernel_shape_f_g = (1, 1) + (self.channels, self.filters_f_g)\n",
    "        print(kernel_shape_f_g)\n",
    "        kernel_shape_h = (1, 1) + (self.channels, self.filters_h)\n",
    "\n",
    "        # Create a trainable weight variable for this layer:\n",
    "        self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n",
    "        self.kernel_f = self.add_weight(shape=kernel_shape_f_g,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_f')\n",
    "        self.kernel_g = self.add_weight(shape=kernel_shape_f_g,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_g')\n",
    "        self.kernel_h = self.add_weight(shape=kernel_shape_h,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_h')\n",
    "        self.bias_f = self.add_weight(shape=(self.filters_f_g,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_F')\n",
    "        self.bias_g = self.add_weight(shape=(self.filters_f_g,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_g')\n",
    "        self.bias_h = self.add_weight(shape=(self.filters_h,),\n",
    "                                      initializer='zeros',\n",
    "                                      name='bias_h')\n",
    "        super(Attention, self).build(input_shape)\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=4,\n",
    "                                    axes={3: input_shape[-1]})\n",
    "        self.built = True\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        def hw_flatten(x):\n",
    "            return K.reshape(x, shape=[K.shape(x)[0], K.shape(x)[1]*K.shape(x)[2], K.shape(x)[-1]])\n",
    "\n",
    "        f = K.conv2d(x,\n",
    "                     kernel=self.kernel_f,\n",
    "                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n",
    "        f = K.bias_add(f, self.bias_f)\n",
    "        g = K.conv2d(x,\n",
    "                     kernel=self.kernel_g,\n",
    "                     strides=(1, 1), padding='same')  # [bs, h, w, c']\n",
    "        g = K.bias_add(g, self.bias_g)\n",
    "        h = K.conv2d(x,\n",
    "                     kernel=self.kernel_h,\n",
    "                     strides=(1, 1), padding='same')  # [bs, h, w, c]\n",
    "        h = K.bias_add(h, self.bias_h)\n",
    "\n",
    "        s = tf.matmul(hw_flatten(g), hw_flatten(f), transpose_b=True)  # # [bs, N, N]\n",
    "\n",
    "        beta = K.softmax(s, axis=-1)  # attention map\n",
    "\n",
    "        o = K.batch_dot(beta, hw_flatten(h))  # [bs, N, C]\n",
    "\n",
    "        o = K.reshape(o, shape=K.shape(x))  # [bs, h, w, C]\n",
    "        x = self.gamma * o + x\n",
    "\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1998 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cc2b622ff78c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                             class_mode='categorical')\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m validation_generator = train_datagen.flow_from_directory(validation_dir,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                                         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "ft_dir = '/home/www/fake_detection/StyleGAN/fine_tune'\n",
    "train_gen_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "ft_gen = train_gen_aug.flow_from_directory(ft_dir,\n",
    "                                            target_size=(img_height, img_width),\n",
    "                                            batch_size=128,\n",
    "                                            shuffle=True,\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
    "                                                        target_size=(img_height, img_width),\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=False,\n",
    "                                                        class_mode='categorical')\n",
    "\n",
    "test50_generator = test_datagen.flow_from_directory(test50_dir,\n",
    "                                                    target_size=(img_height, img_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = load_model('/home/www/fake_detection/model/style_resnetv2.h5')\n",
    "for i in range(2):\n",
    "    model_ft.layers.pop()\n",
    "im_in = Input(shape=(img_width, img_height, 3))\n",
    "\n",
    "base_model = ResNet101V2(include_top=False, weights=None, input_shape=(img_width, img_height, 3), classes=2)\n",
    "base_model.set_weights(model_ft.get_weights())\n",
    "for i in range(len(base_model.layers) - 0):\n",
    "    base_model.layers[i].trainable = False\n",
    "    \n",
    "x1 = base_model(im_in) # (12, 12, 32)\n",
    "########### Mobilenet block bneck 3x3 (32 --> 128) #################\n",
    "expand1 = Conv2D(576, kernel_size=1, strides=1, kernel_regularizer=l2(1e-5), use_bias=False)(x1)\n",
    "expand1 = BatchNormalization()(expand1)\n",
    "expand1 = HardSwish()(expand1)\n",
    "dw1 = DepthwiseConv2D(kernel_size=(3,3), strides=(2,2), padding='same', depthwise_regularizer=l2(1e-5), use_bias=False)(expand1)\n",
    "dw1 = BatchNormalization()(dw1)\n",
    "se_gap1 = GlobalAveragePooling2D()(dw1)\n",
    "se_gap1 = Reshape([1, 1, -1])(se_gap1)\n",
    "se1 = Conv2D(144, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se_gap1)\n",
    "se1 = Activation('relu')(se1)\n",
    "se1 = Conv2D(576, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se1)\n",
    "se1 = HardSigmoid()(se1)\n",
    "se1 = Multiply()([expand1, se1])\n",
    "project1 = HardSwish()(se1)\n",
    "project1 = Conv2D(128, kernel_size=(1, 1), padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(project1)\n",
    "project1 = BatchNormalization()(project1)\n",
    "\n",
    "# ########### Mobilenet block bneck 5x5 (128 --> 128) #################\n",
    "# expand2 = Conv2D(576, kernel_size=1, strides=1, kernel_regularizer=l2(1e-5), use_bias=False)(project1)\n",
    "# expand2 = BatchNormalization()(expand2)\n",
    "# expand2 = HardSwish()(expand2)\n",
    "# dw2 = DepthwiseConv2D(kernel_size=(5,5), strides=(1,1), padding='same', depthwise_regularizer=l2(1e-5), use_bias=False)(expand2)\n",
    "# dw2 = BatchNormalization()(dw2)\n",
    "# se_gap2 = GlobalAveragePooling2D()(dw2)\n",
    "# se_gap2 = Reshape([1, 1, -1])(se_gap2)\n",
    "# se2 = Conv2D(144, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se_gap2)\n",
    "# se2 = Activation('relu')(se2)\n",
    "# se2 = Conv2D(576, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se2)\n",
    "# se2 = HardSigmoid()(se2)\n",
    "# se2 = Multiply()([expand2, se2])\n",
    "# project2 = HardSwish()(se2)\n",
    "# project2 = Conv2D(128, kernel_size=(1, 1), padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(project2)\n",
    "# project2 = BatchNormalization()(project2)\n",
    "# project2 = Add()([project1, project2])\n",
    "\n",
    "# ########### Mobilenet block bneck 5x5 (128 --> 128) #################\n",
    "# expand3 = Conv2D(576, kernel_size=1, strides=1, kernel_regularizer=l2(1e-5), use_bias=False)(project2)\n",
    "# expand3 = BatchNormalization()(expand3)\n",
    "# expand3 = HardSwish()(expand3)\n",
    "# dw3 = DepthwiseConv2D(kernel_size=(5,5), strides=(1,1), padding='same', depthwise_regularizer=l2(1e-5), use_bias=False)(expand3)\n",
    "# dw3 = BatchNormalization()(dw3)\n",
    "# se_gap3 = GlobalAveragePooling2D()(dw3)\n",
    "# se_gap3 = Reshape([1, 1, -1])(se_gap3)\n",
    "# se3 = Conv2D(144, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se_gap3)\n",
    "# se3 = Activation('relu')(se3)\n",
    "# se3 = Conv2D(576, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(se3)\n",
    "# se3 = HardSigmoid()(se3)\n",
    "# se3 = Multiply()([expand3, se3])\n",
    "# project3 = HardSwish()(se3)\n",
    "# project3 = Conv2D(128, kernel_size=(1, 1), padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(project3)\n",
    "# project3 = BatchNormalization()(project3)\n",
    "# project3 = Add()([project2, project3])\n",
    "\n",
    "\n",
    "########## Classification ##########\n",
    "x2 = Conv2D(576, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(project1)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = HardSwish()(x2)\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "x2 = Reshape([1, 1, -1])(x2)\n",
    "\n",
    "\n",
    "# ######### Image Attention Model #########\n",
    "### Block 1 ###\n",
    "x3 = SeparableConv2D(32, kernel_size=(3, 3), strides=(2,2), padding='same', depthwise_regularizer=l2(1e-5), pointwise_regularizer=l2(1e-5), use_bias=False)(im_in)\n",
    "x3 = BatchNormalization()(x3)\n",
    "x3 = HardSwish()(x3)\n",
    "x3 = Attention(32)(x3)\n",
    "\n",
    "### Block 2 ###\n",
    "x4 = SeparableConv2D(64, kernel_size=(3, 3), strides=(2,2), padding='same', depthwise_regularizer=l2(1e-5), pointwise_regularizer=l2(1e-5), use_bias=False)(x3)\n",
    "x4 = BatchNormalization()(x4)\n",
    "x4 = HardSwish()(x4)\n",
    "x4 = Attention(64)(x4)\n",
    "\n",
    "### Block 3 ###\n",
    "x5 = SeparableConv2D(128, kernel_size=(3, 3), strides=(2,2), padding='same', depthwise_regularizer=l2(1e-5), pointwise_regularizer=l2(1e-5), use_bias=False)(x4)\n",
    "x5 = BatchNormalization()(x5)\n",
    "x5 = HardSwish()(x5)\n",
    "x5 = Attention(128)(x5)\n",
    "\n",
    "### final stage ###\n",
    "x6 = Conv2D(576, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5), use_bias=False)(x5)\n",
    "x6 = BatchNormalization()(x6)\n",
    "x6 = HardSwish()(x6)\n",
    "x6 = GlobalAveragePooling2D()(x6)\n",
    "x6 = Reshape([1, 1, -1])(x6)\n",
    "\n",
    "# ######## final addition #########\n",
    "\n",
    "# x2 = Add()([x2, x6])\n",
    "x2 = Conv2D(1020, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5))(x2)\n",
    "x2 = HardSwish()(x2)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = Conv2D(2, kernel_size=1, strides=1, padding='valid', kernel_regularizer=l2(1e-5))(x2)\n",
    "x2 = Activation('softmax')(x2)\n",
    "x2 = Lambda(lambda x: K.squeeze(x, 1))(x2)\n",
    "x2 = Lambda(lambda x: K.squeeze(x, 1))(x2)\n",
    "\n",
    "model_top = Model(inputs=im_in, outputs=x2)\n",
    "model_top.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = SGD(lr=1e-3, momentum=0.9, nesterov=True)\n",
    "optimizer = Adam()\n",
    "model_top.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "callback_list = [EarlyStopping(monitor='val_acc', patience=100), \n",
    "                 ReduceLROnPlateau(monitor='loss', factor=np.sqrt(0.5), cooldown=0, patience=5, min_lr=0.5e-5)]\n",
    "output = model_top.fit_generator(ft_gen, steps_per_epoch=200, epochs=300,\n",
    "                                  validation_data=validation_generator, validation_steps=validation_generator.samples//batch_size, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_score50 = []\n",
    "output_class50 = []\n",
    "answer_class50 = []\n",
    "answer_class50_1 =[]\n",
    "\n",
    "for i in trange(len(test50_generator)):\n",
    "    output50 = model_top.predict_on_batch(test50_generator[i][0])\n",
    "    output_score50.append(output50)\n",
    "    answer_class50.append(test50_generator[i][1])\n",
    "    \n",
    "output_score50 = np.concatenate(output_score50)\n",
    "answer_class50 = np.concatenate(answer_class50)\n",
    "\n",
    "output_class50 = np.argmax(output_score50, axis=1)\n",
    "answer_class50_1 = np.argmax(answer_class50, axis=1)\n",
    "\n",
    "print(output_class50)\n",
    "print(answer_class50_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm50 = confusion_matrix(answer_class50_1, output_class50)\n",
    "report50 = classification_report(answer_class50_1, output_class50)\n",
    "\n",
    "recall50 = cm50[0][0] / (cm50[0][0] + cm50[0][1])\n",
    "fallout50 = cm50[1][0] / (cm50[1][0] + cm50[1][1])\n",
    "\n",
    "fpr50, tpr50, thresholds50 = roc_curve(answer_class50_1, output_score50[:, 1], pos_label=1.)\n",
    "eer50 = brentq(lambda x : 1. - x - interp1d(fpr50, tpr50)(x), 0., 1.)\n",
    "thresh50 = interp1d(fpr50, thresholds50)(eer50)\n",
    "\n",
    "print(report50)\n",
    "print(cm50)\n",
    "print(\"AUROC: %f\" %(roc_auc_score(answer_class50_1, output_score50[:, 1])))\n",
    "print(thresh50)\n",
    "print('test_acc: ', len(output_class50[np.equal(output_class50, answer_class50_1)]) / len(output_class50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
